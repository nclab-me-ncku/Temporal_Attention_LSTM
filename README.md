# Temporal_Attention_LSTM

## Introduction and environment

> * This repository implements temporal attention-aware timestep selection (TTS) method for LSTM. 
> * Our research has exerted this technique in neural decoding. Experimental results show that it could **outperform state-of-the-art neural decoders** on two nonhuman primate datasets. In addition, it also **reduces the computation time for prediction**.
> * Here is our environment
>> * OS: Windows 10
>>* Language: python 3.8.5
>>* Packages: includes in `Pipfile`

## Why we need timestep selection

## What is temporal attention module

## How to use our model

 

